---
phase: 05-android-setup-webrtc
plan: 05
type: execute
wave: 4
depends_on: ["05-03", "05-04"]
files_modified:
  - android/app/src/main/java/com/voiceping/android/data/repository/ChannelRepository.kt
  - android/app/src/main/java/com/voiceping/android/domain/usecase/JoinChannelUseCase.kt
  - android/app/src/main/java/com/voiceping/android/domain/usecase/LeaveChannelUseCase.kt
  - android/app/src/main/java/com/voiceping/android/presentation/channels/ChannelListViewModel.kt
  - android/app/src/main/java/com/voiceping/android/presentation/loading/LoadingScreen.kt
  - android/app/src/main/java/com/voiceping/android/presentation/navigation/NavGraph.kt
autonomous: false

must_haves:
  truths:
    - "App connects to WebSocket server after login and initializes mediasoup Device"
    - "User can toggle a channel on to join it via WebSocket signaling"
    - "User can toggle a channel off to leave it (consumers closed, transport cleaned up)"
    - "When someone transmits on joined channel, speaker name appears with pulsing animation"
    - "Audio from transmitting user plays through device earpiece"
    - "Selecting a different channel deselects the previous one (single channel only)"
    - "Bottom bar updates to show current speaker when someone is transmitting"
  artifacts:
    - path: "android/app/src/main/java/com/voiceping/android/data/repository/ChannelRepository.kt"
      provides: "Channel join/leave with mediasoup integration and speaker observation"
      contains: "observeSpeakerChanges"
    - path: "android/app/src/main/java/com/voiceping/android/domain/usecase/JoinChannelUseCase.kt"
      provides: "Channel join orchestration (signaling + mediasoup)"
      contains: "joinChannel"
    - path: "android/app/src/main/java/com/voiceping/android/domain/usecase/LeaveChannelUseCase.kt"
      provides: "Channel leave with cleanup"
      contains: "leaveChannel"
  key_links:
    - from: "ChannelListViewModel.kt"
      to: "ChannelRepository.kt"
      via: "JoinChannelUseCase/LeaveChannelUseCase for channel operations"
      pattern: "JoinChannelUseCase|LeaveChannelUseCase"
    - from: "ChannelRepository.kt"
      to: "SignalingClient.kt"
      via: "WebSocket signaling for JOIN_CHANNEL, LEAVE_CHANNEL"
      pattern: "signalingClient.request.*JOIN_CHANNEL"
    - from: "ChannelRepository.kt"
      to: "MediasoupClient.kt"
      via: "createRecvTransport + consumeAudio for incoming audio"
      pattern: "mediasoupClient.createRecvTransport|mediasoupClient.consumeAudio"
    - from: "LoadingScreen.kt"
      to: "SignalingClient.kt"
      via: "WebSocket connect + mediasoup init during loading phase"
      pattern: "signalingClient.connect|mediasoupClient.initialize"
---

<objective>
Wire the complete channel join and audio receive flow: LoadingScreen establishes WebSocket connection and initializes mediasoup Device, ChannelRepository orchestrates channel join/leave via signaling + mediasoup transport, speaker changes update the UI in real-time, and audio plays through earpiece. This plan connects all prior plans into an end-to-end working system.

Purpose: This is the integration plan that proves the Android app can receive audio from the existing server. All prior plans built components — this plan wires them together.
Output: End-to-end audio receive: user joins channel, hears transmissions, sees speaker name, audio plays through earpiece.
</objective>

<execution_context>
@C:\Users\jotha\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\jotha\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/phases/05-android-setup-webrtc/05-RESEARCH.md
@.planning/phases/05-android-setup-webrtc/05-03-SUMMARY.md
@.planning/phases/05-android-setup-webrtc/05-04-SUMMARY.md
@src/shared/protocol.ts

Reference research Pattern 4 (mediasoup Receive Transport), Code Example 3 (SPEAKER_CHANGED handling), and Pitfall 4 (AudioTrack disposal).

Server signaling flow for channel join:
1. Client sends JOIN_CHANNEL with { channelId }
2. Server responds with channel state (users, current speaker)
3. Client sends GET_ROUTER_CAPABILITIES (if not already loaded)
4. Client sends CREATE_TRANSPORT with { channelId, direction: "recv" }
5. Server responds with transport parameters
6. Client creates RecvTransport locally
7. On onConnect callback: Client sends CONNECT_TRANSPORT with { transportId, dtlsParameters }
8. Server broadcasts SPEAKER_CHANGED when someone starts/stops PTT
9. Client sends CONSUME with { producerId, rtpCapabilities } to receive audio
10. Server responds with consumer parameters
11. Client creates Consumer, calls resume(), audio plays

Server broadcast for speaker change (from handlers.ts):
{
  type: "speaker-changed",
  data: {
    channelId: "...",
    speakerUserId: "..." | null,
    speakerName: "..." | null,
    producerId: "..." | null
  }
}
When speaker stops: speakerUserId is null.
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create ChannelRepository and use cases for join/leave/speaker</name>
  <files>
    android/app/src/main/java/com/voiceping/android/data/repository/ChannelRepository.kt
    android/app/src/main/java/com/voiceping/android/domain/usecase/JoinChannelUseCase.kt
    android/app/src/main/java/com/voiceping/android/domain/usecase/LeaveChannelUseCase.kt
  </files>
  <action>
    **ChannelRepository.kt:** @Singleton with @Inject constructor. Inject SignalingClient, MediasoupClient, AudioRouter.

    Properties:
    - _currentSpeaker: MutableStateFlow<User?>(null) — exposed as StateFlow
    - _joinedChannelId: MutableStateFlow<String?>(null) — exposed as StateFlow
    - private var speakerObserverJob: Job? = null

    Methods:

    **joinChannel(channelId: String): Result<Unit>**
    1. Request JOIN_CHANNEL from server: signalingClient.request(JOIN_CHANNEL, mapOf("channelId" to channelId))
    2. Check response for error — if server returns error, return Result.failure
    3. Set up audio routing: audioRouter.requestAudioFocus(), audioRouter.setEarpieceMode()
    4. Create receive transport: mediasoupClient.createRecvTransport(channelId)
    5. Start observing speaker changes for this channel
    6. Update _joinedChannelId to channelId
    7. Return Result.success(Unit)

    **leaveChannel(channelId: String): Result<Unit>**
    1. Cancel speakerObserverJob
    2. Clean up mediasoup: mediasoupClient.cleanup()
    3. Release audio: audioRouter.releaseAudioFocus(), audioRouter.resetAudioMode()
    4. Request LEAVE_CHANNEL from server: signalingClient.request(LEAVE_CHANNEL, mapOf("channelId" to channelId))
    5. Clear _currentSpeaker to null
    6. Clear _joinedChannelId to null
    7. Return Result.success(Unit)

    **observeSpeakerChanges(channelId: String)**
    Cancel any existing speakerObserverJob. Launch new coroutine collecting signalingClient.messages:
    - Filter for SPEAKER_CHANGED type
    - Extract channelId, speakerUserId, speakerName, producerId from message data
    - If channelId matches and speakerUserId is not null:
      - Update _currentSpeaker to User(speakerUserId, speakerName)
      - Call mediasoupClient.consumeAudio(producerId, speakerUserId) to receive their audio
    - If speakerUserId is null (speaker stopped):
      - Update _currentSpeaker to null
      - Close the consumer for that producer (mediasoupClient.closeConsumer)
    - Store the job in speakerObserverJob for cancellation on leave

    **disconnectAll()**
    - If _joinedChannelId is not null, call leaveChannel
    - Cancel speakerObserverJob

    **JoinChannelUseCase.kt:** @Inject constructor, inject ChannelRepository.
    - operator fun invoke(channelId: String): Result<Unit> = channelRepository.joinChannel(channelId)

    **LeaveChannelUseCase.kt:** @Inject constructor, inject ChannelRepository.
    - operator fun invoke(channelId: String): Result<Unit> = channelRepository.leaveChannel(channelId)
  </action>
  <verify>
    ChannelRepository.joinChannel sends JOIN_CHANNEL, sets up audio routing (earpiece), creates recv transport, starts speaker observation. leaveChannel cleans up in correct order (cancel observer -> cleanup mediasoup -> release audio -> send LEAVE_CHANNEL). Speaker changes trigger consumeAudio for incoming audio.
  </verify>
  <done>
    Channel join/leave flow works end-to-end: signaling, mediasoup transport, audio routing, speaker change observation. Single-channel constraint enforced (leave previous before joining new).
  </done>
</task>

<task type="auto">
  <name>Task 2: Wire LoadingScreen WebSocket connection and update ChannelListViewModel</name>
  <files>
    android/app/src/main/java/com/voiceping/android/presentation/loading/LoadingScreen.kt
    android/app/src/main/java/com/voiceping/android/presentation/channels/ChannelListViewModel.kt
    android/app/src/main/java/com/voiceping/android/presentation/navigation/NavGraph.kt
  </files>
  <action>
    **LoadingScreen.kt:** Update from Plan 02 placeholder to actual WebSocket connection.

    Create LoadingViewModel (@HiltViewModel) — inject SignalingClient, MediasoupClient, PreferencesManager, TokenManager, AuthRepository.
    - UiState: sealed class with Connecting, Connected(savedEventId: String?), Failed(message: String)
    - connectToServer(): Launch coroutine:
      1. Check if token needs refresh: if tokenManager.needsRefresh(), call authRepository.refreshTokenWithRetry(). If refresh fails, emit Failed with message.
      2. Get server URL from BuildConfig.SERVER_URL
      3. Call signalingClient.connect(serverUrl). If throws, emit Failed.
      4. Wait for connectionState to become CONNECTED (with 15-second timeout). If timeout, emit Failed.
      5. Call mediasoupClient.initialize(). If throws, log warning but continue (initialize can be retried on channel join).
      6. Emit Connected with PreferencesManager.getLastEventId()
    - Auto-called on screen composition via LaunchedEffect

    LoadingScreen composable:
    - Dark background, centered VoicePing logo, "Connecting..." text, CircularProgressIndicator
    - On Connected: navigate to channels/{savedEventId} if savedEventId exists, else navigate to events
    - On Failed: show error message with "Retry" button (calls connectToServer again) and "Logout" button (clears tokens, navigates to login)

    **ChannelListViewModel.kt:** Update from Plan 04 to wire real channel operations.
    - Add injection: ChannelRepository, JoinChannelUseCase, LeaveChannelUseCase
    - toggleChannel(channel): Update to call actual use cases:
      1. If channel is already joined (_joinedChannel.value?.id == channel.id): call LeaveChannelUseCase(channel.id), set _joinedChannel to null
      2. Else: if another channel is joined, call LeaveChannelUseCase on it first. Then call JoinChannelUseCase(channel.id). If success, set _joinedChannel to channel. If failure, show error.
    - Observe ChannelRepository.currentSpeaker StateFlow — update _currentSpeaker accordingly. Also update the channel in _channels list that matches the joined channelId to reflect currentSpeaker.
    - Observe ChannelRepository.joinedChannelId — sync with _joinedChannel
    - On ViewModel onCleared(): call channelRepository.disconnectAll()

    **NavGraph.kt:** Final update to ensure LoadingScreen navigates correctly based on connection outcome. Add LoadingViewModel to the loading composable. Ensure all navigation arguments (eventId) pass correctly.
  </action>
  <verify>
    LoadingScreen connects WebSocket, initializes mediasoup, then navigates to events or channels based on saved event. ChannelListViewModel toggleChannel calls real JoinChannelUseCase/LeaveChannelUseCase. Speaker changes from ChannelRepository flow to UI (pulsing indicator, bottom bar). ViewModel cleanup disconnects on destroy.
  </verify>
  <done>
    End-to-end flow works: Login -> Loading (WebSocket + mediasoup init) -> Channel list -> Toggle channel -> Audio plays through earpiece -> Speaker name shows with pulse. All Phase 5 success criteria satisfied.
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>
    Complete Android app with: login flow, event picker, channel list with team grouping, channel join via WebSocket + mediasoup, audio receive through earpiece, speaker indicators, bottom bar, profile drawer, connection status indicators.
  </what-built>
  <how-to-verify>
    1. Open project in Android Studio from `android/` directory
    2. Configure SERVER_URL in build.gradle.kts to point to your running VoicePing server
    3. Build and run on Android emulator (API 26+) or physical device
    4. Verify login screen: dark theme, logo, email/password fields, login button
    5. Login with valid credentials — should see loading screen then channel list
    6. Verify channel list: channels grouped by team headers, checkbox toggles, user count
    7. Toggle a channel on — app should connect to channel via WebSocket
    8. From another client (web browser): transmit on the same channel
    9. Verify: speaker name appears with pulsing animation on channel row and bottom bar
    10. Verify: audio plays through earpiece (hold phone to ear)
    11. Toggle channel off — speaker indicator should disappear
    12. Test profile drawer: swipe or tap profile icon, verify menu items
    13. Test event switching: Switch Event -> pick different event -> channel list updates
    14. Close and reopen app: should auto-login and skip to channel list (saved event)

    If mediasoup wrapper (libmediasoup-android 0.7.0) has compatibility issues:
    - Check logcat for mediasoup/WebRTC errors
    - Verify Device.load() succeeds with server's router capabilities
    - Verify transport connection state progression (new -> connecting -> connected)
    - If audio doesn't play: check consumer.resume() is called, check AudioManager mode
  </how-to-verify>
  <resume-signal>Type "approved" if the app works end-to-end, or describe any issues found.</resume-signal>
</task>

</tasks>

<verification>
1. LoadingScreen connects WebSocket with JWT token and initializes mediasoup Device
2. Token refresh happens proactively at 55 minutes (before 1-hour expiry)
3. Channel join sends JOIN_CHANNEL + creates recv transport + starts speaker observation
4. Channel leave cleans up: cancel observer -> close consumers -> close transport -> send LEAVE_CHANNEL
5. SPEAKER_CHANGED broadcasts trigger consumeAudio for incoming audio producers
6. Audio plays through earpiece (MODE_IN_COMMUNICATION, speakerphone off)
7. Speaker name + pulsing animation appear on channel row and bottom bar
8. Single channel constraint: toggling new channel auto-leaves previous
9. ViewModel cleanup disconnects on destroy
10. Build compiles and runs on API 26+ device
</verification>

<success_criteria>
- User can login, see channels, join a channel, and hear audio from other transmitters
- Speaker indicators (pulsing animation + name) appear in real-time
- Audio routes to earpiece by default
- All 7 Phase 5 success criteria from ROADMAP.md are satisfied
- Human verification confirms end-to-end functionality
</success_criteria>

<output>
After completion, create `.planning/phases/05-android-setup-webrtc/05-05-SUMMARY.md`
</output>

---
phase: 02-user-management-access-control
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - src/server/auth/rateLimiter.ts
  - src/server/mediasoup/workerPool.ts
  - src/server/mediasoup/transportManager.ts
autonomous: true

must_haves:
  truths:
    - "Repeated failed auth attempts are progressively slowed down, not hard-locked"
    - "Server-side jitter buffer smooths audio for degraded networks"
    - "Worker pool is optimized for single-server 1000+ user target"
  artifacts:
    - path: "src/server/auth/rateLimiter.ts"
      provides: "Progressive rate limiting for auth operations"
      exports: ["RateLimiter"]
    - path: "src/server/mediasoup/workerPool.ts"
      provides: "Optimized worker pool for higher concurrency"
    - path: "src/server/mediasoup/transportManager.ts"
      provides: "Jitter buffer configuration on WebRTC transports"
  key_links:
    - from: "src/server/auth/rateLimiter.ts"
      to: "src/server/state/redisClient.ts"
      via: "Redis backend for rate limit counters"
      pattern: "getRedisClient"
    - from: "src/server/mediasoup/transportManager.ts"
      to: "src/server/config.ts"
      via: "Jitter buffer config values"
      pattern: "config\\.jitterBuffer"
---

<objective>
Add rate limiting with progressive slowdown (never hard lockout), configure server-side jitter buffer for audio reliability on degraded networks, and optimize the mediasoup worker pool for the 1000+ concurrent user target.

Purpose: Rate limiting prevents brute force while keeping legitimate users unblocked. Jitter buffer ensures critical audio gets through on bad networks. Worker optimization sets the foundation for handling 100+ concurrent users in testing.
Output: RateLimiter class, updated transport manager with jitter buffer, optimized worker pool settings.
</objective>

<execution_context>
@C:\Users\jotha\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\jotha\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/02-user-management-access-control/02-CONTEXT.md
@.planning/phases/02-user-management-access-control/02-RESEARCH.md
@src/server/mediasoup/workerPool.ts
@src/server/mediasoup/transportManager.ts
@src/server/config.ts
@src/server/state/redisClient.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create progressive rate limiter with Redis backend</name>
  <files>
    src/server/auth/rateLimiter.ts
  </files>
  <action>
Install rate-limiter-flexible: `npm install rate-limiter-flexible`

Create src/server/auth/rateLimiter.ts implementing progressive slowdown per user decision (lenient rate limiting with progressive slowdown on repeated failures, NOT hard lockout).

1. **Import** rate-limiter-flexible's RateLimiterRedis class.

2. **RateLimiter class** with these limiters:
   - `connectionLimiter`: Max 20 WebSocket connections per IP per minute. Uses RateLimiterRedis with keyPrefix 'rl:conn'.
   - `authLimiter`: Max 10 auth attempts per IP per 15 minutes. Progressive penalty: each failure after 3rd adds exponential delay (1s, 2s, 4s, 8s, 16s, max 30s). Uses RateLimiterRedis with keyPrefix 'rl:auth'.
   - `pttLimiter`: Max 60 PTT actions per user per minute (prevent abuse). Uses RateLimiterRedis with keyPrefix 'rl:ptt'.

3. **consumeConnection(ip: string) -> { allowed: boolean, retryAfterMs?: number }:** Check connection rate limit. If exceeded, return allowed=false with retryAfterMs.

4. **consumeAuth(ip: string) -> { allowed: boolean, retryAfterMs?: number, penalty?: number }:** Check auth rate limit. On failure, increase penalty counter. Return delay to apply before processing.

5. **consumePtt(userId: string) -> { allowed: boolean }:** Check PTT action rate limit.

6. **recordAuthFailure(ip: string) -> void:** Increment failure counter for progressive slowdown. Stored in Redis key `rl:fail:{ip}` with 15-minute TTL.

7. **recordAuthSuccess(ip: string) -> void:** Reset failure counter on successful auth.

8. **getSlowdownMs(ip: string) -> number:** Calculate progressive delay based on failure count. Formula: min(1000 * 2^(failures-3), 30000) for failures > 3, else 0.

CRITICAL per user decision: NEVER hard-lock accounts. Always allow retry after delay. Progressive slowdown only, no hard blocks. This prevents DoS vector where attacker locks out legitimate users.

Use Redis backend so rate limits persist across server restarts. Initialize lazily (create Redis-backed limiters only when first called, so rate limiting gracefully degrades if Redis is temporarily unavailable).
  </action>
  <verify>
Run `npm install rate-limiter-flexible` and verify it's in package.json dependencies. Run `npx tsc --noEmit` to verify compilation. Verify file exports RateLimiter class with consumeConnection, consumeAuth, consumePtt, recordAuthFailure, recordAuthSuccess methods.
  </verify>
  <done>
RateLimiter class exists with progressive slowdown (no hard lockout). rate-limiter-flexible installed. Connection, auth, and PTT rate limiters configured with Redis backend. Progressive delay formula: 1s, 2s, 4s, 8s, 16s, 30s cap. TypeScript compiles clean.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add jitter buffer config and optimize worker pool for 1000+ users</name>
  <files>
    src/server/mediasoup/transportManager.ts
    src/server/mediasoup/workerPool.ts
  </files>
  <action>
**Transport Manager - Jitter Buffer:**

Modify src/server/mediasoup/transportManager.ts to configure server-side jitter buffer on WebRTC transports.

When creating WebRTC transports via createWebRtcTransport(), add these parameters to the transport creation options:
- `initialAvailableOutgoingBitrate`: 600000 (600kbps, sufficient for Opus voice)
- For recv transports, mediasoup handles jitter buffering internally via its pacing mechanism

Add a method `configureJitterBuffer(transportId: string, bufferMs: number)` that:
- Validates bufferMs is within config.jitterBuffer.minMs (40) and config.jitterBuffer.maxMs (80)
- Logs the configured jitter buffer value
- Note: mediasoup handles jitter buffering at the RTP level; the configuration is via transport-level settings and Opus codec parameters (FEC, DTX already configured in Phase 1)

The primary jitter mitigation for mediasoup is:
1. Opus FEC (already enabled in Phase 1 - opusFec: true)
2. NACK support (already in codec config rtcpFeedback)
3. Transport-CC for bandwidth estimation (already in codec config)
4. Setting appropriate `initialAvailableOutgoingBitrate` to prevent congestion

Import config from '../config' and use config.jitterBuffer values.

**Worker Pool Optimization:**

Modify src/server/mediasoup/workerPool.ts for single-server scalability:

1. Add method `getWorkerStats() -> { workerId, routerCount, pid, cpuUsage }[]` that returns stats for each worker. This enables monitoring under load.

2. Add method `getOptimalWorkerCount() -> number` that calculates recommended workers based on CPU count and expected load. Formula: Math.max(1, Math.min(os.cpus().length, Math.floor(os.cpus().length * 0.75))) -- leave 25% CPU headroom for Node.js event loop and OS.

3. Update the worker selection strategy to be load-aware: instead of pure round-robin, select the worker with the fewest active routers when creating new channel routers. Add a `routerCounts` Map tracking routers per worker. Fall back to round-robin if counts are equal.

4. Add `logPoolStatus()` method that logs worker count, total routers, and per-worker router distribution.

Keep all existing methods intact. Only add new functionality.
  </action>
  <verify>
Run `npx tsc --noEmit` to verify compilation. Check that transportManager.ts imports config and references jitterBuffer settings. Check that workerPool.ts has getWorkerStats() and getOptimalWorkerCount() methods.
  </verify>
  <done>
Transport manager has initialAvailableOutgoingBitrate set for voice-optimized bandwidth. Worker pool has load-aware selection, getWorkerStats(), getOptimalWorkerCount(), and logPoolStatus() methods. 25% CPU headroom reserved. TypeScript compiles clean.
  </done>
</task>

</tasks>

<verification>
1. `npx tsc --noEmit` passes with zero errors
2. `npm ls rate-limiter-flexible` shows the package installed
3. src/server/auth/rateLimiter.ts exports RateLimiter class
4. Worker pool has load-aware selection and stats methods
5. Transport manager references jitter buffer config values
</verification>

<success_criteria>
- Rate limiter progressively slows repeated failures (1s, 2s, 4s... up to 30s) without ever hard-locking
- Worker pool reports stats and uses load-aware worker selection
- Transport creation includes voice-optimized bandwidth settings
- All changes compile cleanly with no regressions
</success_criteria>

<output>
After completion, create `.planning/phases/02-user-management-access-control/02-02-SUMMARY.md`
</output>

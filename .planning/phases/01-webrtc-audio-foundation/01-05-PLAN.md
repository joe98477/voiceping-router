---
phase: 01-webrtc-audio-foundation
plan: 05
type: execute
wave: 3
depends_on: ["01-01"]
files_modified:
  - src/client/mediasoup/device.ts
  - src/client/mediasoup/transportClient.ts
  - src/client/audio/microphone.ts
  - src/client/signaling/signalingClient.ts
autonomous: true

must_haves:
  truths:
    - "mediasoup-client Device initializes with server router capabilities"
    - "Send and receive WebRTC transports are created through signaling"
    - "Microphone audio is captured with PTT-optimized constraints"
    - "WebSocket signaling client sends/receives typed messages with request-response correlation"
  artifacts:
    - path: "src/client/mediasoup/device.ts"
      provides: "mediasoup-client Device initialization and management"
      exports: ["MediasoupDevice"]
      min_lines: 40
    - path: "src/client/mediasoup/transportClient.ts"
      provides: "Client-side send/recv transport management"
      exports: ["TransportClient"]
      min_lines: 60
    - path: "src/client/audio/microphone.ts"
      provides: "getUserMedia with PTT-optimized audio constraints"
      exports: ["MicrophoneManager"]
      min_lines: 40
    - path: "src/client/signaling/signalingClient.ts"
      provides: "WebSocket client with typed signaling protocol"
      exports: ["SignalingClient"]
      min_lines: 80
  key_links:
    - from: "src/client/mediasoup/device.ts"
      to: "src/client/signaling/signalingClient.ts"
      via: "Requests router capabilities from server"
      pattern: "GET_ROUTER_CAPABILITIES|getRouterCapabilities"
    - from: "src/client/mediasoup/transportClient.ts"
      to: "src/client/signaling/signalingClient.ts"
      via: "Creates transports via signaling requests"
      pattern: "CREATE_TRANSPORT|createTransport"
    - from: "src/client/audio/microphone.ts"
      to: "navigator.mediaDevices"
      via: "getUserMedia for audio capture"
      pattern: "getUserMedia"
    - from: "src/client/signaling/signalingClient.ts"
      to: "src/shared/protocol.ts"
      via: "Uses SignalingType for message typing"
      pattern: "SignalingType|SignalingMessage"
---

<objective>
Implement the client-side audio pipeline: mediasoup-client device initialization, WebRTC transport management, microphone capture with PTT-optimized constraints, and the WebSocket signaling client for server communication.

Purpose: The client side handles audio capture from the user's microphone and audio playback from other users, mediated through mediasoup-client's WebRTC stack. These modules are the browser-side counterpart to the server's mediasoup SFU.

Output: Four client modules providing device setup, transport management, microphone capture, and signaling communication.
</objective>

<execution_context>
@C:\Users\jotha\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\jotha\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-webrtc-audio-foundation/01-RESEARCH.md
@.planning/phases/01-webrtc-audio-foundation/01-01-SUMMARY.md
@src/shared/protocol.ts
@src/shared/types.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Signaling client and mediasoup device</name>
  <files>
    src/client/signaling/signalingClient.ts
    src/client/mediasoup/device.ts
  </files>
  <action>
    1. Create `src/client/signaling/signalingClient.ts`:

    Class `SignalingClient` wrapping browser WebSocket with typed signaling protocol.

    **Constructor:** Takes WebSocket URL and JWT token.

    **Connection:**
    - `async connect()`: Create WebSocket with token in protocol header (`new WebSocket(url, ['voiceping', token])`)
    - Return promise that resolves on `open` event, rejects on `error`
    - Track connection state: `connecting`, `connected`, `disconnected`

    **Request-response pattern:**
    - `async request(type: SignalingType, data?: object): Promise<SignalingMessage>`:
      - Generate unique message ID (crypto.randomUUID() or counter)
      - Send `{ type, id, data }`
      - Return promise that resolves when response with matching `id` arrives
      - Timeout after 10 seconds with descriptive error
      - Store pending requests in Map<string, { resolve, reject, timeout }>

    **Event handling:**
    - On message: Parse JSON, check if it's a response (has `id` matching pending request) or a server push (no matching request)
    - For responses: resolve pending request promise
    - For server pushes: emit typed events using EventTarget or custom EventEmitter
    - `on(type: SignalingType, callback)`: Register handler for server push messages
    - `off(type: SignalingType, callback)`: Remove handler

    **Send helpers (typed wrappers around request):**
    - `async joinChannel(channelId: string)`: request(JOIN_CHANNEL, { channelId })
    - `async leaveChannel(channelId: string)`: request(LEAVE_CHANNEL, { channelId })
    - `async getRouterCapabilities(channelId: string)`: request(GET_ROUTER_CAPABILITIES, { channelId })
    - `async createTransport(channelId: string, direction: 'send' | 'recv')`: request(CREATE_TRANSPORT, { channelId, direction })
    - `async connectTransport(transportId: string, dtlsParameters: object)`: request(CONNECT_TRANSPORT, { transportId, dtlsParameters })
    - `async produce(transportId: string, kind: string, rtpParameters: object, channelId: string)`: request(PRODUCE, { transportId, kind, rtpParameters, channelId })
    - `async consume(channelId: string, producerId: string)`: request(CONSUME, { channelId, producerId })
    - `async pttStart(channelId: string)`: request(PTT_START, { channelId })
    - `async pttStop(channelId: string)`: request(PTT_STOP, { channelId })

    **State:**
    - `isConnected(): boolean`
    - `close()`: Close WebSocket
    - Do NOT implement reconnection here -- Plan 06 adds that as a wrapper

    2. Create `src/client/mediasoup/device.ts`:

    Class `MediasoupDevice` wrapping mediasoup-client Device.

    **Constructor:** Takes `SignalingClient` instance.

    **Initialization:**
    - `async load(channelId: string)`:
      - Request router capabilities from server via signaling
      - Create mediasoup-client `Device` instance
      - Call `device.load({ routerRtpCapabilities })` with capabilities from server
      - Store channelId association
      - Return device RTP capabilities (for server to create consumers)
    - Handle `device.loaded` state -- don't re-load if already loaded for same capabilities

    **Device access:**
    - `getDevice()`: Return underlying Device instance
    - `getRtpCapabilities()`: Return loaded capabilities
    - `canProduce(kind: 'audio')`: Check if device supports audio production
    - `isLoaded()`: Check if device has been loaded with capabilities

    **Error handling:**
    - If `device.load()` fails: log error, throw descriptive error
    - If browser doesn't support required codecs: throw with message about browser incompatibility
  </action>
  <verify>
    - `npx tsc --noEmit` compiles without errors
    - SignalingClient has typed methods for all SignalingType values
    - Request-response pattern uses unique IDs with timeout
    - MediasoupDevice wraps mediasoup-client Device correctly
  </verify>
  <done>
    SignalingClient provides typed WebSocket communication with request-response correlation. MediasoupDevice initializes mediasoup-client with server capabilities. Both compile and export correct types.
  </done>
</task>

<task type="auto">
  <name>Task 2: Transport client and microphone manager</name>
  <files>
    src/client/mediasoup/transportClient.ts
    src/client/audio/microphone.ts
  </files>
  <action>
    1. Create `src/client/mediasoup/transportClient.ts`:

    Class `TransportClient` managing client-side send and receive transports.

    **Constructor:** Takes `MediasoupDevice` and `SignalingClient` instances.

    **Send transport:**
    - `async createSendTransport(channelId: string)`:
      - Request transport creation from server (direction: 'send')
      - Create send transport on device using returned options: `device.createSendTransport({ id, iceParameters, iceCandidates, dtlsParameters })`
      - Wire transport events:
        - `connect`: Send CONNECT_TRANSPORT to server with dtlsParameters, callback on success
        - `produce`: Send PRODUCE to server with kind/rtpParameters, callback with { id } from server
        - `connectionstatechange`: Log state changes. On 'failed': log error (reconnection handled by Plan 06)
      - Store transport reference

    **Receive transport:**
    - `async createRecvTransport(channelId: string)`:
      - Request transport creation from server (direction: 'recv')
      - Create recv transport on device: `device.createRecvTransport({ id, iceParameters, iceCandidates, dtlsParameters })`
      - Wire transport events:
        - `connect`: Send CONNECT_TRANSPORT to server with dtlsParameters
        - `connectionstatechange`: Log state changes
      - Store transport reference

    **Audio production:**
    - `async produceAudio(track: MediaStreamTrack, channelId: string): Promise<string>`:
      - Produce audio on send transport with codec options:
        - `opusStereo: false` (mono)
        - `opusDtx: false` (CRITICAL: disable DTX per research -- prevents first-word cutoff)
        - `opusFec: true` (forward error correction for packet loss)
        - `opusMaxPlaybackRate: 48000`
      - Return producer ID
      - Producer starts paused (server controls via PTT)

    **Audio consumption:**
    - `async consumeAudio(producerId: string, channelId: string): Promise<{ consumer: object; track: MediaStreamTrack }>`:
      - Request consumer creation from server
      - Create consumer on recv transport: `recvTransport.consume({ id, producerId, kind, rtpParameters })`
      - Resume consumer
      - Return consumer object and its audio track

    **Cleanup:**
    - `async closeSendTransport()`: Close send transport, clear producer
    - `async closeRecvTransport()`: Close recv transport, clear consumers
    - `async closeAll()`: Close everything

    2. Create `src/client/audio/microphone.ts`:

    Class `MicrophoneManager` for microphone access and audio stream management.

    **Permission handling:**
    - `async checkPermission(): Promise<'granted' | 'denied' | 'prompt'>`:
      - Use `navigator.permissions.query({ name: 'microphone' as PermissionName })` if available
      - Fall back to 'prompt' if permissions API not supported (Safari)
      - Per research Pitfall 3: Check permission state BEFORE calling getUserMedia

    **Audio capture:**
    - `async getAudioTrack(): Promise<MediaStreamTrack>`:
      - Call `navigator.mediaDevices.getUserMedia()` with PTT-optimized constraints:
        ```
        {
          audio: {
            echoCancellation: true,
            noiseSuppression: true,
            autoGainControl: true,
            sampleRate: 48000,
            channelCount: 1
          },
          video: false
        }
        ```
      - Cache the stream and track
      - Return the audio track
      - Handle errors:
        - `NotAllowedError`: User denied permission -- throw with message "Microphone permission denied. Please allow microphone access in browser settings."
        - `NotFoundError`: No microphone -- throw with message "No microphone found. Please connect a microphone."
        - `NotReadableError`: Microphone in use -- throw with message "Microphone is in use by another application."

    **Track management:**
    - `muteTrack()`: Set `track.enabled = false` (stops sending audio without destroying stream)
    - `unmuteTrack()`: Set `track.enabled = true`
    - `isMuted(): boolean`: Return !track.enabled
    - `stopTrack()`: Call `track.stop()` and `stream.getTracks().forEach(t => t.stop())` -- full release of microphone
    - `isActive(): boolean`: Check if track is live (track.readyState === 'live')

    **Cleanup:**
    - `release()`: Stop all tracks, clear references
    - Important: Always release microphone when done to free hardware resource and remove browser indicator
  </action>
  <verify>
    - `npx tsc --noEmit` compiles without errors
    - TransportClient creates send/recv transports with correct event wiring
    - Producer uses opusDtx: false (critical for PTT)
    - MicrophoneManager handles all three getUserMedia error types
    - Audio constraints specify 48kHz mono
  </verify>
  <done>
    TransportClient manages send/recv WebRTC transports with proper mediasoup-client event wiring. Audio production uses PTT-optimized Opus settings (DTX disabled, FEC enabled, mono). MicrophoneManager handles permissions gracefully and captures audio with noise suppression. All client audio infrastructure is in place.
  </done>
</task>

</tasks>

<verification>
1. `npx tsc --noEmit` compiles all client modules
2. SignalingClient implements request-response with timeout
3. MediasoupDevice loads with router capabilities
4. TransportClient creates send/recv transports
5. Audio production disables DTX (opusDtx: false)
6. MicrophoneManager captures audio at 48kHz mono
7. All error cases have descriptive messages
</verification>

<success_criteria>
- SignalingClient provides typed WebSocket messaging with request-response correlation
- MediasoupDevice initializes from server router capabilities
- Send transport produces audio with DTX disabled and FEC enabled
- Receive transport consumes audio and returns playable MediaStreamTrack
- Microphone permission check before capture attempt
- All getUserMedia errors handled with user-facing messages
- Cleanup methods release all resources (tracks, transports, sockets)
</success_criteria>

<output>
After completion, create `.planning/phases/01-webrtc-audio-foundation/01-05-SUMMARY.md`
</output>

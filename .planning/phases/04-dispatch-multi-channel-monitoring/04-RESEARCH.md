# Phase 4: Dispatch Multi-Channel Monitoring - Research

**Researched:** 2026-02-07
**Domain:** Multi-channel monitoring and audio management for dispatch operators
**Confidence:** HIGH

## Summary

Phase 4 implements dispatch operator multi-channel monitoring (10-50 simultaneous channels) with selective mute/unmute, per-channel PTT, and visual activity indicators. This research focused on three critical domains:

1. **WebRTC scalability**: How browsers handle 50 simultaneous WebRTC transport pairs and audio streams
2. **Audio mixing architecture**: How to play multiple unmuted channels without artifacts
3. **UI patterns**: How dispatch consoles present 50 channels with real-time activity indicators

The existing architecture from Phase 3 already supports multi-channel monitoring - each ChannelCard creates its own ConnectionManager with dedicated WebRTC transports. The primary challenge is **scale** (50 channels vs. 10) and **UX** (dispatch operators need visual scanning of all channels, not one-at-a-time PTT).

**Key findings:**
- **Browser limits**: No hard WebRTC connection limit, but resource constraints (CPU/memory) bottleneck before protocol limits. 50 transport pairs is feasible on modern hardware.
- **Audio mixing**: Browser automatically mixes multiple MediaStreamTrack outputs to single audio device. Web Audio API not required for basic multi-stream playback.
- **Server scalability**: mediasoup can handle 500+ consumers per worker. 50 dispatch channels = ~100-150 consumers total (manageable on single worker).
- **Channel limit bypass**: Current `defaultSimultaneousChannelLimit: 10` must be raised or bypassed for DISPATCH role.

**Primary recommendation:** Extend existing Phase 3 architecture with: (1) DISPATCH role bypass for 10-channel limit, (2) compact grid UI for 50 channels, (3) per-channel mute toggle state, (4) visual activity indicators using existing SPEAKER_CHANGED events. No fundamental architecture changes required.

## Standard Stack

The established libraries/tools for this domain:

### Core
| Library | Version | Purpose | Why Standard |
|---------|---------|---------|--------------|
| mediasoup-client | 3.7.x | WebRTC SFU client | Already in use (Phase 1), proven scalability 500+ consumers per worker |
| React | 18.3.1 | UI framework | Already in use (Phase 3), ChannelCard component reusable |
| Web Audio API | Native | Audio stream analysis (optional) | Built-in browser API for visualizing activity indicators |

### Supporting
| Library | Version | Purpose | When to Use |
|---------|---------|---------|-------------|
| CSS Grid | Native | Multi-channel layout | For 50-channel grid view (no library needed) |
| React Virtualization | Optional | Large list rendering | Only if 50+ channels cause performance issues |

### Alternatives Considered
| Instead of | Could Use | Tradeoff |
|------------|-----------|----------|
| Multiple ConnectionManagers | Single ConnectionManager with multiplexing | Would require significant refactoring of Phase 1 architecture. Current approach (one ConnectionManager per channel) is simpler and proven. |
| Native audio playback | Web Audio API mixing | Web Audio API adds complexity for custom mixing, but browser already mixes multiple streams natively. Only needed for advanced features (volume normalization, ducking). |
| CSS Grid layout | react-window virtualization | Virtualization adds complexity. With 50 channels, CSS Grid should perform adequately on modern browsers. |

**Installation:**
```bash
# No new dependencies required
# All libraries already installed in Phase 3
```

## Architecture Patterns

### Recommended Project Structure
```
web-ui/src/
â”œâ”€â”€ pages/
â”‚   â”œâ”€â”€ Dispatch.jsx           # Existing page (Phase 3 - GENERAL users)
â”‚   â””â”€â”€ DispatchMonitoring.jsx # NEW: Multi-channel monitoring for DISPATCH role
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ ChannelCard.jsx         # Existing (reuse with compact variant)
â”‚   â”œâ”€â”€ ChannelGrid.jsx         # NEW: Grid layout for 50 channels
â”‚   â””â”€â”€ ActivityIndicator.jsx  # NEW: Visual indicator for active channels
â”œâ”€â”€ hooks/
â”‚   â”œâ”€â”€ useChannelConnection.js # Existing (no changes needed)
â”‚   â”œâ”€â”€ useMultiChannel.js      # NEW: Manage 50 channel connections
â”‚   â””â”€â”€ useChannelMute.js       # NEW: Per-channel mute state
â””â”€â”€ context/
    â””â”€â”€ ChannelContext.jsx      # Existing (extend for mute state)
```

### Pattern 1: Multi-Channel Connection Management

**What:** Manage 10-50 ConnectionManager instances simultaneously without resource exhaustion.

**When to use:** When dispatch user needs to monitor many channels concurrently.

**Example:**
```javascript
// web-ui/src/hooks/useMultiChannel.js
import { useState, useEffect, useCallback } from 'react';
import { useChannelConnection } from './useChannelConnection';

/**
 * Manage multiple simultaneous channel connections
 * Creates one ConnectionManager per channel
 */
export const useMultiChannel = (channels, wsUrl, token) => {
  // Track which channels are muted (local UI state, NOT server state)
  const [mutedChannels, setMutedChannels] = useState(new Set());

  // Toggle mute for a channel
  const toggleMute = useCallback((channelId) => {
    setMutedChannels(prev => {
      const next = new Set(prev);
      if (next.has(channelId)) {
        next.delete(channelId);
      } else {
        next.add(channelId);
      }
      return next;
    });
  }, []);

  // Mute/unmute audio output for a channel (client-side only)
  const setChannelMuted = useCallback((channelId, muted) => {
    setMutedChannels(prev => {
      const next = new Set(prev);
      if (muted) {
        next.add(channelId);
      } else {
        next.delete(channelId);
      }
      return next;
    });
  }, []);

  return {
    mutedChannels,
    toggleMute,
    setChannelMuted,
  };
};
```

**Key insight:** Each ChannelCard manages its own ConnectionManager (existing pattern from Phase 3). Multi-channel monitoring is just rendering 50 ChannelCards instead of 10. No architectural changes needed.

### Pattern 2: Client-Side Audio Muting

**What:** Selectively mute audio output from specific channels without disconnecting.

**When to use:** When dispatch user wants to focus on specific channels while monitoring others visually.

**Example:**
```javascript
// Extend ChannelCard to support audio muting
import { useEffect, useRef } from 'react';

const ChannelCard = ({ channel, wsUrl, token, isMuted, onToggleMute }) => {
  const { connectionManager } = useChannelConnection(channel.id, wsUrl, token);
  const audioElementRef = useRef(null);

  // When connectionManager creates audio element, apply mute state
  useEffect(() => {
    if (!connectionManager) return;

    // Get audio element from TransportClient consumer
    const transportClient = connectionManager.getTransportClient();
    if (!transportClient) return;

    const consumers = transportClient.getAllConsumers();
    consumers.forEach(consumer => {
      // Each consumer has a MediaStreamTrack
      const track = consumer.track;

      // Create or get audio element for this track
      if (!audioElementRef.current) {
        const audio = document.createElement('audio');
        audio.srcObject = new MediaStream([track]);
        audio.autoplay = true;
        audioElementRef.current = audio;
      }

      // Apply mute state
      if (audioElementRef.current) {
        audioElementRef.current.muted = isMuted;
      }
    });
  }, [connectionManager, isMuted]);

  return (
    <div className="channel-card channel-card--compact">
      <button onClick={onToggleMute}>
        {isMuted ? 'ðŸ”‡ Unmute' : 'ðŸ”Š Mute'}
      </button>
      {/* Rest of ChannelCard */}
    </div>
  );
};
```

**Alternative approach (simpler):** Use Web Audio API to create audio context and control gain per channel.

```javascript
// Web Audio API approach for per-channel volume control
useEffect(() => {
  if (!connectionManager) return;

  const audioContext = new AudioContext();
  const gainNode = audioContext.createGain();

  // Set gain based on mute state
  gainNode.gain.value = isMuted ? 0 : 1;

  const transportClient = connectionManager.getTransportClient();
  const consumers = transportClient.getAllConsumers();

  consumers.forEach(consumer => {
    const track = consumer.track;
    const stream = new MediaStream([track]);
    const source = audioContext.createMediaStreamSource(stream);

    // Connect: source -> gain -> destination (speakers)
    source.connect(gainNode);
    gainNode.connect(audioContext.destination);
  });

  return () => {
    audioContext.close();
  };
}, [connectionManager, isMuted]);
```

### Pattern 3: Visual Activity Indicators

**What:** Show which channels have active speakers without relying on audio cues alone.

**When to use:** Dispatch operator needs to scan 50 channels visually to identify activity.

**Example:**
```javascript
// web-ui/src/components/ActivityIndicator.jsx
const ActivityIndicator = ({ channelState }) => {
  const isActive = channelState?.isBusy || false;
  const speakerName = channelState?.speakerName || null;

  return (
    <div className={`activity-indicator ${isActive ? 'active' : 'idle'}`}>
      {isActive && (
        <>
          <div className="activity-indicator__pulse" />
          <span className="activity-indicator__speaker">{speakerName}</span>
        </>
      )}
    </div>
  );
};
```

**CSS Animation for visual attention:**
```css
.activity-indicator.active {
  background-color: #ff6b00;
  animation: pulse 1s infinite;
}

@keyframes pulse {
  0%, 100% { opacity: 1; }
  50% { opacity: 0.6; }
}
```

**Advanced: Audio level visualization using Web Audio API:**
```javascript
// Optional: Show audio level meter per channel
import { useEffect, useRef } from 'react';

const useAudioLevel = (connectionManager) => {
  const [audioLevel, setAudioLevel] = useState(0);
  const analyserRef = useRef(null);

  useEffect(() => {
    if (!connectionManager) return;

    const audioContext = new AudioContext();
    const analyser = audioContext.createAnalyser();
    analyser.fftSize = 256;
    analyserRef.current = analyser;

    const transportClient = connectionManager.getTransportClient();
    const consumers = transportClient.getAllConsumers();

    consumers.forEach(consumer => {
      const stream = new MediaStream([consumer.track]);
      const source = audioContext.createMediaStreamSource(stream);
      source.connect(analyser);
    });

    // Poll audio level
    const dataArray = new Uint8Array(analyser.frequencyBinCount);
    const updateLevel = () => {
      analyser.getByteFrequencyData(dataArray);
      const average = dataArray.reduce((a, b) => a + b) / dataArray.length;
      setAudioLevel(average / 255); // Normalize to 0-1
      requestAnimationFrame(updateLevel);
    };
    updateLevel();

    return () => {
      audioContext.close();
    };
  }, [connectionManager]);

  return audioLevel;
};
```

### Pattern 4: Grid Layout for 50 Channels

**What:** Responsive grid that shows 50 channels without scrolling on typical dispatch operator displays.

**When to use:** When dispatch operator needs to see all monitored channels at once.

**Example:**
```javascript
// web-ui/src/components/ChannelGrid.jsx
const ChannelGrid = ({ channels, wsUrl, token, mutedChannels, onToggleMute }) => {
  return (
    <div className="channel-grid">
      {channels.map(channel => (
        <ChannelCard
          key={channel.id}
          channel={channel}
          wsUrl={wsUrl}
          token={token}
          isMuted={mutedChannels.has(channel.id)}
          onToggleMute={() => onToggleMute(channel.id)}
          variant="compact" // Smaller cards for grid view
        />
      ))}
    </div>
  );
};
```

**CSS Grid Layout:**
```css
.channel-grid {
  display: grid;
  grid-template-columns: repeat(auto-fill, minmax(200px, 1fr));
  gap: 12px;
  padding: 16px;
  overflow-y: auto;
}

/* Compact variant for grid view */
.channel-card--compact {
  min-height: 120px;
  padding: 8px;
}

.channel-card--compact .channel-card__header {
  font-size: 14px;
}

.channel-card--compact .ptt-button {
  font-size: 12px;
  padding: 6px 12px;
}
```

**Responsive breakpoints:**
```css
/* 1080p display: 10 columns (5x10 = 50 channels) */
@media (min-width: 1920px) {
  .channel-grid {
    grid-template-columns: repeat(10, 1fr);
  }
}

/* Standard HD: 8 columns */
@media (min-width: 1280px) and (max-width: 1919px) {
  .channel-grid {
    grid-template-columns: repeat(8, 1fr);
  }
}

/* Laptop: 6 columns */
@media (max-width: 1279px) {
  .channel-grid {
    grid-template-columns: repeat(6, 1fr);
  }
}
```

### Anti-Patterns to Avoid

- **Creating all 50 ConnectionManagers on page load:** Mount channels on-demand or with progressive initialization to avoid network spike. Consider lazy loading channels as user scrolls (if using virtualization).
- **Using localStorage for mute state:** Mute preferences are session-specific, use React state or sessionStorage. Don't persist to server (client-side UI preference only).
- **Mixing audio server-side:** Browser already mixes multiple MediaStreamTrack outputs. No need for server-side mixing or Web Audio API unless custom features needed (volume normalization, ducking, etc.).
- **Real-time audio level meters for all 50 channels:** Computationally expensive. Use visual indicators (pulse animation) triggered by SPEAKER_CHANGED events instead. Audio level meters only for focused/selected channels.
- **Single WebSocket for all channels:** Each ConnectionManager creates its own WebSocket. This is correct - if one channel's connection fails, others remain active.

## Don't Hand-Roll

Problems that look simple but have existing solutions:

| Problem | Don't Build | Use Instead | Why |
|---------|-------------|-------------|-----|
| Audio stream mixing | Custom audio merger | Browser's native multi-stream playback | Browsers automatically mix multiple HTMLAudioElement or MediaStream outputs to single audio device |
| Visual activity detection | Audio level polling | SPEAKER_CHANGED events from server | Server already tracks active speaker, emit events rather than analyze audio client-side |
| 50-channel grid layout | Custom virtualization | CSS Grid with overflow-y: auto | CSS Grid is performant for 50-200 items. Only virtualize if >100 channels |
| Per-channel mute | MediaStreamTrack.enabled = false | HTMLAudioElement.muted or Web Audio GainNode | Disabling track stops receiving data. Muting audio element keeps data flowing (faster unmute) |
| Connection lifecycle | Custom reconnect per channel | Existing ReconnectingSignalingClient | Already handles reconnection, session recovery per channel |

**Key insight:** Phase 1-3 architecture already supports multi-channel. The challenge is UX (grid layout, visual indicators), not architecture. Don't rebuild core components.

## Common Pitfalls

### Pitfall 1: Channel Limit Enforcement Blocks Dispatch Users

**What goes wrong:** DISPATCH user tries to join 50 channels but server denies after 10 channels due to `defaultSimultaneousChannelLimit: 10` (AUTHZ-004).

**Why it happens:** Server config applies same limit to all roles. DISPATCH users need higher limit or bypass.

**How to avoid:**
- Option 1: Add `dispatchSimultaneousChannelLimit: 50` config, check role in handlers.ts
- Option 2: Bypass limit check for DISPATCH role: `if (user.role !== UserRole.DISPATCH && ctx.channels.size >= config.channels.defaultSimultaneousChannelLimit)`

**Warning signs:**
- DISPATCH user sees "Cannot join more than 10 channels simultaneously" error
- Only first 10 channels connect, rest fail silently

**Example fix:**
```typescript
// src/server/signaling/handlers.ts
async handleJoinChannel(ctx: ClientContext, message: SignalingMessage): Promise<void> {
  // ...existing permission check...

  // Enforce simultaneous channel limit (bypass for DISPATCH role)
  const isDispatch = ctx.role === UserRole.DISPATCH;
  const channelLimit = isDispatch
    ? config.channels.dispatchSimultaneousChannelLimit || 50
    : config.channels.defaultSimultaneousChannelLimit;

  if (ctx.channels.size >= channelLimit) {
    logger.warn(`User ${ctx.userId} denied access to channel ${channelId} (simultaneous channel limit)`);
    this.sendError(ctx, message.id, `Cannot join more than ${channelLimit} channels simultaneously`);
    return;
  }
  // ...rest of handler...
}
```

### Pitfall 2: Browser Resource Exhaustion with 50 Transport Pairs

**What goes wrong:** Browser becomes sluggish, high CPU/memory usage, eventual tab crash.

**Why it happens:** 50 channels = 100 WebRTC transports (50 send + 50 recv) = significant CPU for ICE candidates, DTLS handshakes, RTP processing.

**How to avoid:**
- **Progressive initialization:** Don't connect all 50 channels at once. Connect 10-20 channels initially, load rest on-demand.
- **Monitor browser performance:** Use Chrome Task Manager to track memory/CPU per tab.
- **Hardware requirements:** Document minimum specs (8GB RAM, modern CPU) for dispatch stations.

**Warning signs:**
- Browser fans spin up loudly
- Chrome DevTools shows high CPU in WebRTC threads
- Audio stuttering or dropouts
- Tab becomes unresponsive

**Example fix (progressive initialization):**
```javascript
// Load channels in batches of 10 every 2 seconds
const useProgressiveChannelLoad = (allChannels, wsUrl, token) => {
  const [loadedChannels, setLoadedChannels] = useState([]);

  useEffect(() => {
    let offset = 0;
    const batchSize = 10;

    const loadBatch = () => {
      if (offset >= allChannels.length) return;

      const batch = allChannels.slice(offset, offset + batchSize);
      setLoadedChannels(prev => [...prev, ...batch]);
      offset += batchSize;

      if (offset < allChannels.length) {
        setTimeout(loadBatch, 2000); // 2-second delay between batches
      }
    };

    loadBatch();
  }, [allChannels]);

  return loadedChannels;
};
```

### Pitfall 3: Audio Mixing Artifacts with Multiple Active Channels

**What goes wrong:** When 2+ channels have active speakers, audio becomes distorted, overlapping voices unintelligible.

**Why it happens:** Browser mixes all audio streams at equal volume. Human ear can't separate 3+ simultaneous speakers.

**How to avoid:**
- **Priority muting:** Auto-mute low-priority channels when high-priority channel becomes active (ducking).
- **Volume normalization:** Use Web Audio API to normalize volume across channels.
- **UI guidance:** Show warning: "Multiple channels active - mute channels to reduce audio overload"

**Warning signs:**
- User reports "can't understand anyone when multiple channels are talking"
- Audio sounds muddy or distorted
- Dispatch operator manually mutes all but one channel during busy periods

**Example fix (auto-ducking):**
```javascript
// Auto-mute lower-priority channels when high-priority channel becomes active
useEffect(() => {
  const activeChannels = Object.entries(channelStates)
    .filter(([_, state]) => state.isBusy)
    .map(([id]) => id);

  if (activeChannels.length > 1) {
    // Find highest priority active channel
    const priorityChannel = activeChannels.find(id =>
      channels.find(ch => ch.id === id)?.priority === 'HIGH'
    );

    if (priorityChannel) {
      // Mute all other active channels
      activeChannels.forEach(id => {
        if (id !== priorityChannel && !mutedChannels.has(id)) {
          setChannelMuted(id, true);
        }
      });
    }
  }
}, [channelStates]);
```

### Pitfall 4: Mediasoup Worker Overload with 50 Channels

**What goes wrong:** Server CPU spikes, audio latency increases, consumers drop.

**Why it happens:** 50 dispatch users each monitoring 50 channels = 2,500 consumer connections on single mediasoup worker.

**How to avoid:**
- **Worker distribution:** Distribute channels across multiple mediasoup workers (already configured in Phase 1).
- **Monitor server metrics:** Track CPU per worker, consumers per router.
- **Scale horizontally:** Run multiple audio-server instances if single server can't handle load.

**Warning signs:**
- Server CPU consistently >80%
- Audio dropouts reported by users
- mediasoup logs show "Consumer closed" warnings
- Increased latency (>500ms)

**Server capacity calculation:**
```
Single mediasoup worker handles ~500 consumers
50 channels Ã— 10 dispatch users = 500 consumers (at capacity)
50 channels Ã— 20 dispatch users = 1,000 consumers (need 2 workers)
```

### Pitfall 5: Forgetting to Clean Up 50 ConnectionManager Instances

**What goes wrong:** User navigates away from dispatch monitoring page, but WebSocket connections remain open. Memory leak, server sessions orphaned.

**Why it happens:** React useEffect cleanup function not called, or cleanup doesn't properly disconnect.

**How to avoid:**
- **Verify cleanup in useChannelConnection:** Ensure `manager.disconnect()` is called in cleanup.
- **Test navigation:** Navigate away from dispatch page and verify all WebSockets close (check Chrome DevTools Network tab).
- **Server-side timeout:** Server should close idle connections after X minutes.

**Warning signs:**
- Chrome DevTools shows 50+ WebSocket connections after navigating away
- Server logs show increasing session count without corresponding user count
- Server memory grows over time

## Code Examples

Verified patterns from official sources:

### Multi-Channel Monitoring Page
```javascript
// web-ui/src/pages/DispatchMonitoring.jsx
import React from 'react';
import { useParams } from 'react-router-dom';
import { useAuth } from '../hooks/useAuth';
import { useChannels } from '../context/ChannelContext';
import { useMultiChannel } from '../hooks/useMultiChannel';
import ChannelGrid from '../components/ChannelGrid';

const DispatchMonitoring = () => {
  const { eventId } = useParams();
  const { user, token } = useAuth();
  const { channels } = useChannels(); // All channels user is authorized for

  // WebSocket URL construction
  const wsUrl = `${window.location.protocol === 'https:' ? 'wss:' : 'ws:'}//${window.location.host}/ws`;

  // Multi-channel state management
  const { mutedChannels, toggleMute } = useMultiChannel(channels, wsUrl, token);

  return (
    <div className="dispatch-monitoring">
      <header className="dispatch-monitoring__header">
        <h1>Multi-Channel Monitoring</h1>
        <div className="dispatch-monitoring__stats">
          <span>Monitoring: {channels.length} channels</span>
          <span>Muted: {mutedChannels.size} channels</span>
          <span>Active: {Object.values(channelStates).filter(s => s.isBusy).length}</span>
        </div>
      </header>

      <ChannelGrid
        channels={channels}
        wsUrl={wsUrl}
        token={token}
        mutedChannels={mutedChannels}
        onToggleMute={toggleMute}
      />
    </div>
  );
};

export default DispatchMonitoring;
```

### Compact ChannelCard Variant
```javascript
// Extend existing ChannelCard with compact variant
const ChannelCard = ({ channel, wsUrl, token, isMuted, onToggleMute, variant = 'default' }) => {
  const { connectionState, error, connectionManager } = useChannelConnection(
    channel.id,
    wsUrl,
    token
  );

  const { channelStates } = useChannels();
  const channelState = channelStates[channel.id] || { isBusy: false, speakerName: null };

  // ... PTT handlers ...

  if (variant === 'compact') {
    return (
      <div className={`channel-card channel-card--compact ${channelState.isBusy ? 'active' : ''}`}>
        <div className="channel-card__header">
          <span className="channel-card__name">{channel.name}</span>
          <button
            className="channel-card__mute-btn"
            onClick={onToggleMute}
            aria-label={isMuted ? 'Unmute' : 'Mute'}
          >
            {isMuted ? 'ðŸ”‡' : 'ðŸ”Š'}
          </button>
        </div>

        {channelState.isBusy && (
          <div className="channel-card__activity">
            <div className="activity-pulse" />
            <span>{channelState.speakerName}</span>
          </div>
        )}

        <button
          className="ptt-button ptt-button--compact"
          disabled={connectionState !== 'connected'}
          onMouseDown={handlePttPress}
          onMouseUp={handlePttRelease}
        >
          PTT
        </button>
      </div>
    );
  }

  // Default variant (existing full-size card)
  return (
    <div className="channel-card">
      {/* Existing ChannelCard JSX */}
    </div>
  );
};
```

## State of the Art

| Old Approach | Current Approach | When Changed | Impact |
|--------------|------------------|--------------|--------|
| Single audio stream per user | Multiple simultaneous audio streams | WebRTC 1.0 (2017+) | Enables multi-channel monitoring without server-side mixing |
| Server-side audio mixing | Client-side browser mixing | Modern browsers (2020+) | Reduces server CPU, shifts mixing to client |
| Manual audio element management | MediaStream auto-playback | WebRTC spec | Simpler audio routing, browser handles mixing |
| Desktop-only dispatch consoles | Web-based dispatch consoles | 2024+ | Cloud-native, accessible from any device |
| Per-connection signaling | Multiplexed signaling | WebRTC 1.0 | One WebSocket can handle multiple channels (but current arch uses one per channel for isolation) |

**Deprecated/outdated:**
- Server-side audio mixing: Modern browsers handle client-side mixing natively
- Flash-based audio: WebRTC replaced Flash for real-time audio
- Manual WebSocket reconnection: ReconnectingSignalingClient handles this

**Current best practices (2026):**
- Client-side audio mixing via native browser capabilities
- Visual activity indicators over audio-only (accessibility + cognitive load)
- Progressive channel loading for large channel counts
- Role-based channel limits (general users: 10, dispatch: 50+)

## Open Questions

Things that couldn't be fully resolved:

1. **Optimal number of simultaneous connections per client**
   - What we know: mediasoup-client can handle 500+ consumers. Browser handles multiple audio streams natively.
   - What's unclear: At what point does browser performance degrade? 50 channels? 100 channels?
   - Recommendation: Start with 50-channel limit for dispatch users. Monitor client-side performance metrics. If performance issues arise, implement progressive loading or virtualization.

2. **Audio ducking/priority strategy**
   - What we know: Multiple simultaneous speakers create unintelligible audio.
   - What's unclear: Should system auto-mute lower-priority channels when high-priority channel becomes active? Or leave muting to user discretion?
   - Recommendation: Implement manual mute toggles first (simpler, gives user control). Add auto-ducking in future phase if users request it.

3. **Server-side channel user count optimization**
   - What we know: Each dispatch user monitoring 50 channels creates 50 consumer connections server-side.
   - What's unclear: Does mediasoup optimize when multiple users consume same producer?
   - Recommendation: Trust mediasoup's internal optimization (router.pipeToRouter for multi-worker scenarios). Monitor server CPU and scale horizontally if needed.

4. **Visualization library for audio level meters**
   - What we know: Web Audio API AnalyserNode can extract audio levels. Libraries like LiveKit's AudioVisualizer exist.
   - What's unclear: Is audio level visualization necessary for dispatch monitoring, or are binary active/idle indicators sufficient?
   - Recommendation: Start with binary indicators (SPEAKER_CHANGED events). Add audio level meters if users specifically request them.

## Sources

### Primary (HIGH confidence)
- [mediasoup Scalability Documentation](https://mediasoup.org/documentation/v3/scalability/) - Worker capacity (~500 consumers per worker)
- [WebRTC Stream Limits Investigation](https://tensorworks.com.au/blog/webrtc-stream-limits-investigation/) - Browser WebRTC connection limits
- Project source code:
  - `src/client/ConnectionManager.ts` - Per-channel WebRTC lifecycle
  - `web-ui/src/hooks/useChannelConnection.js` - React hook for ConnectionManager
  - `web-ui/src/components/ChannelCard.jsx` - Existing channel UI component
  - `src/server/config.ts` - `defaultSimultaneousChannelLimit: 10` (line 142)
  - `src/server/signaling/handlers.ts` - Channel join limit enforcement (line 142)

### Secondary (MEDIUM confidence)
- [WebRTC RTCPeerConnection: One to rule them all, or one per stream?](https://bloggeek.me/webrtc-rtcpeerconnection-one-per-stream/) - WebRTC architecture patterns
- [Web Audio API Multiple RTCPeerConnection Audio Streams Mixing](https://webrtchacks.com/web-audio-conference/) - Client-side audio mixing patterns
- [LiveKit AudioVisualizer React Component](https://docs.livekit.io/reference/components/react/component/audiovisualizer/) - Audio visualization patterns
- [SmartPTT Dispatcher Guide](https://smartptt.com/wp-content/uploads/2023/12/SmartPTT-Dispatcher-Guide-4.pdf) - Commercial dispatch console UX patterns
- [Hytera Smart Dispatch](https://www.hytera.com/systems/smartdispatch) - Multi-channel monitoring features

### Tertiary (LOW confidence)
- WebSearch results for "dispatch operator multi-channel monitoring PTT best practices 2026" - Industry trends, not technical implementation details

## Metadata

**Confidence breakdown:**
- Standard stack: HIGH - mediasoup-client, React already in use; browser audio mixing is native
- Architecture: HIGH - Verified from existing Phase 3 codebase (ConnectionManager, ChannelCard patterns)
- Scalability: MEDIUM - mediasoup docs confirm 500+ consumers/worker, but real-world 50-channel client performance needs testing
- UI patterns: MEDIUM - CSS Grid proven for large layouts, but dispatch-specific UX patterns vary by vendor

**Research date:** 2026-02-07
**Valid until:** 2026-03-07 (30 days, WebRTC and mediasoup are stable)

**Critical decisions for planning:**
- DISPATCH role must bypass or have higher `simultaneousChannelLimit` (50 vs 10)
- Compact ChannelCard variant needed for grid layout
- Per-channel mute state managed client-side (React state, not server)
- Visual activity indicators driven by existing SPEAKER_CHANGED events
- Progressive channel loading recommended for >30 channels (avoid network spike)

**No new npm dependencies required for basic multi-channel monitoring.** Optional: LiveKit components or custom Web Audio API integration for advanced audio visualization.
